{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Yx94pYizS32-FcxwuHilXEkQvxG_P6zq",
      "authorship_tag": "ABX9TyNvpi45KEnb2kbAjoXst0K3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexisL321/band_member_detection_detectron2/blob/main/coding_task_frame.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHLqy_m0WIWi",
        "outputId": "1ae06154-51d4-4d7d-f9f8-af2886ea6a38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from imutils.video import FileVideoStream\n",
        "import time\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import yaml\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "aIvdy3Af6Lg3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract frames from video\n",
        "pathName = '/content/drive/My Drive/Drone Footage_Coding Task/Drone Footage/11 9 flights/'\n",
        "videos = glob.glob(pathName + '*.MP4')\n",
        "videos = videos[10:-1]\n",
        "for video in videos:\n",
        "  numFrame = 0\n",
        "  fvs = FileVideoStream(video).start()\n",
        "  maxFrame = 500\n",
        "  time.sleep(1.0)\n",
        "  start = time.time()\n",
        "  videoName = video.split('/')[7].split('.')[0]\n",
        "  outFolder = '/content/drive/My Drive/Frames/'+videoName\n",
        "  os.makedirs(outFolder, exist_ok = True)\n",
        "  while fvs.more():\n",
        "    frame = fvs.read()\n",
        "    #print(frame)\n",
        "    outFile = os.path.join(outFolder, \"%s_%i.jpg\"%(videoName, numFrame))\n",
        "    #print(outFile)\n",
        "    if np.any(frame):\n",
        "      cv2.imwrite(outFile, frame)\n",
        "    else:\n",
        "      break\n",
        "    if numFrame % 1000 == 0:\n",
        "      print(f\"{numFrame} processed, {np.any(frame)}\")\n",
        "\n",
        "    numFrame += 1\n",
        "    if numFrame > maxFrame:\n",
        "      break\n",
        "  \n",
        "  totalTime = time.time() - start\n",
        "  print(\"Total time: {:.2f}s\", format(totalTime))\n"
      ],
      "metadata": {
        "id": "0m4bL3zGJ2ey",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "071c6443-7935-4efe-d354-04fa4ed1cfed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 processed, True\n",
            "Total time: {:.2f}s 145.8224196434021\n",
            "0 processed, True\n",
            "Total time: {:.2f}s 154.9542942047119\n",
            "0 processed, True\n",
            "Total time: {:.2f}s 153.94745755195618\n",
            "0 processed, True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert json files to coc json format\n",
        "import json\n",
        "from google.colab import files\n",
        "src = list(files.upload().values())[0]\n",
        "#open('COCOJson.py','wb').write(src)\n",
        "#import labelbox_processing\n",
        "#import COCOJson\n",
        "#import json_functions\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "1D7mae8yw6C6",
        "outputId": "e9c7030a-3b2d-4eb0-9b40-6d81531ed743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f170727e-341a-4fef-a8c1-544a4d5359de\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f170727e-341a-4fef-a8c1-544a4d5359de\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving inference.py to inference.py\n",
            "Saving PrecisionRecallEvaluator.py to PrecisionRecallEvaluator.py\n",
            "Saving LossEvalHook.py to LossEvalHook.py\n",
            "Saving GroundtruthVisualizer.py to GroundtruthVisualizer.py\n",
            "Saving LRScheduler.py to LRScheduler.py\n",
            "Saving DetectionDatasetMapper.py to DetectionDatasetMapper.py\n",
            "Saving DetectionTrainer.py to DetectionTrainer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jsondir = '/content/drive/My Drive/Drone Footage_Coding Task/All Labels/'\n",
        "jsonFiles = glob.glob(jsondir + \"*.json\")\n",
        "os.makedirs('/content/drive/My Drive/coco/cocojson', exist_ok = True)\n",
        "os.makedirs('/content/drive/My Drive/coco/images', exist_ok = True)\n",
        "cocoFolder = '/content/drive/My Drive/coco/cocojson';\n",
        "\n",
        "for jsonfile in jsonFiles:\n",
        "  jsonfileName = os.path.basename(jsonfile)\n",
        "  imageFolder = os.path.join('/content/drive/My Drive/coco/images', jsonfileName.split('_')[1])\n",
        "  os.makedirs(imageFolder, exist_ok = True)\n",
        "  cocojsonFile = os.path.join(cocoFolder, \"coco_\"+ jsonfileName)\n",
        "  labelbox_processing.labelbox_to_coco(jsonfile, cocojsonFile, imageFolder, \n",
        "                                       description = jsonfileName.split('_')[1],\n",
        "                                       date = \"March,2023\", overwrite = False, verbose = True,\n",
        "                                       custom_class_reader = None)\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIwW_g5pKzJY",
        "outputId": "6f7b861a-3ece-4b38-ea68-ef0309d137d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 band_member\n",
            "2 object_e_g_backpacks_belongings\n",
            "3 observer_non_band_member\n",
            "saving at /content/drive/My Drive/coco/cocojson/coco_export-2023-02-28T19_22_17.380Z.json\n",
            "4234 annotations from 11 images saved.\n",
            "1 band_member\n",
            "2 object_e_g_backpacks_belongings\n",
            "3 observer_non_band_member\n",
            "saving at /content/drive/My Drive/coco/cocojson/coco_export-2023-02-28T19_25_46.471Z.json\n",
            "8670 annotations from 20 images saved.\n",
            "1 band_member\n",
            "2 object_e_g_backpacks_belongings\n",
            "3 observer_non_band_member\n",
            "saving at /content/drive/My Drive/coco/cocojson/coco_export-2023-02-28T19_26_37.868Z.json\n",
            "5059 annotations from 15 images saved.\n",
            "1 band_member\n",
            "2 object_e_g_backpacks_belongings\n",
            "3 observer_non_band_member\n",
            "saving at /content/drive/My Drive/coco/cocojson/coco_export-2023-02-28T19_29_07.431Z.json\n",
            "8068 annotations from 20 images saved.\n",
            "1 band_member\n",
            "2 object_e_g_backpacks_belongings\n",
            "3 observer_non_band_member\n",
            "saving at /content/drive/My Drive/coco/cocojson/coco_export-2023-03-02T01_21_56.571Z.json\n",
            "8817 annotations from 17 images saved.\n",
            "1 band_member\n",
            "2 object_e_g_backpacks_belongings\n",
            "3 observer_non_band_member\n",
            "saving at /content/drive/My Drive/coco/cocojson/coco_export-2023-03-02T01_32_56.762Z (1).json\n",
            "1975 annotations from 8 images saved.\n",
            "1 band_member\n",
            "2 object_e_g_backpacks_belongings\n",
            "3 observer_non_band_member\n",
            "saving at /content/drive/My Drive/coco/cocojson/coco_export-2023-03-02T01_37_56.327Z.json\n",
            "7254 annotations from 20 images saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data\n",
        "jsondir = '/content/drive/My Drive/coco/cocojson/'\n",
        "jsonFiles = glob.glob(jsondir + \"*.json\")\n",
        "jsonFileArray = [jsonfile for jsonfile in jsonFiles]\n",
        "output_file = os.path.join(jsondir, \"all_annotations1.json\")\n",
        "json_functions.combine_jsons(jsonFileArray, output_file)\n",
        "\n",
        "fracValidation = 0.2\n",
        "json_functions.create_train_val_split(output_file, fracValidation, \n",
        "                                      train_name= \"train.json\", \n",
        "                                      val_name = \"val.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-KxIRQbDxA4",
        "outputId": "08c2b4cf-fd9a-41fd-972e-def592821cab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 555 annotated images in the JSON files.\n",
            "555 images added to new .json\n",
            "220385 annotations added to new .json\n",
            "There are 555 annotated images.\n",
            "444 training images with 176512 annotations.\n",
            "111 validation images with 43873 annotations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install detectron2\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juQ9KYUZ4CNX",
        "outputId": "e37eb5d0-d91b-4fae-aa17-6a18a903ded3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-j4115ls5\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-j4115ls5\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit 072713649a9b0069c10aad1aaab819112e8f1e2e\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.9/dist-packages (from detectron2==0.6) (8.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from detectron2==0.6) (3.7.1)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from detectron2==0.6) (2.0.6)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.9/dist-packages (from detectron2==0.6) (2.2.0)\n",
            "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.9/dist-packages (from detectron2==0.6) (0.1.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.9/dist-packages (from detectron2==0.6) (0.8.10)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (from detectron2==0.6) (2.2.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.9/dist-packages (from detectron2==0.6) (4.65.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.9/dist-packages (from detectron2==0.6) (2.11.2)\n",
            "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.9/dist-packages (from detectron2==0.6) (0.1.5.post20221221)\n",
            "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.9/dist-packages (from detectron2==0.6) (0.1.9)\n",
            "Requirement already satisfied: omegaconf>=2.1 in /usr/local/lib/python3.9/dist-packages (from detectron2==0.6) (2.3.0)\n",
            "Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.9/dist-packages (from detectron2==0.6) (1.3.2)\n",
            "Requirement already satisfied: black in /usr/local/lib/python3.9/dist-packages (from detectron2==0.6) (23.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from detectron2==0.6) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.22.4)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.9/dist-packages (from hydra-core>=1.1->detectron2==0.6) (4.9.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.9/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (2.7.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->detectron2==0.6) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->detectron2==0.6) (1.0.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->detectron2==0.6) (3.0.9)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->detectron2==0.6) (5.12.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->detectron2==0.6) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->detectron2==0.6) (4.39.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.9/dist-packages (from black->detectron2==0.6) (1.0.0)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from black->detectron2==0.6) (0.11.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.9/dist-packages (from black->detectron2==0.6) (3.1.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from black->detectron2==0.6) (8.1.3)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from black->detectron2==0.6) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.9/dist-packages (from black->detectron2==0.6) (4.5.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard->detectron2==0.6) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard->detectron2==0.6) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard->detectron2==0.6) (1.51.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tensorboard->detectron2==0.6) (0.40.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard->detectron2==0.6) (63.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard->detectron2==0.6) (0.6.1)\n",
            "Requirement already satisfied: protobuf<4,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorboard->detectron2==0.6) (3.19.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard->detectron2==0.6) (2.2.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard->detectron2==0.6) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard->detectron2==0.6) (1.8.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard->detectron2==0.6) (2.16.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (5.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->detectron2==0.6) (3.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard->detectron2==0.6) (6.0.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (1.26.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install pyyaml==5.1\n",
        "import sys, os, distutils.core\n",
        "# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities.\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n",
        "!git clone 'https://github.com/facebookresearch/detectron2'\n",
        "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
        "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
        "sys.path.insert(0, os.path.abspath('./detectron2'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogiuAoUzLXpu",
        "outputId": "39064dd1-da39-4058-f9c3-cf2a5bd238c0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml==5.1 in /usr/local/lib/python3.9/dist-packages (5.1)\n",
            "Cloning into 'detectron2'...\n",
            "remote: Enumerating objects: 14935, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 14935 (delta 7), reused 13 (delta 3), pack-reused 14915\u001b[K\n",
            "Receiving objects: 100% (14935/14935), 6.05 MiB | 19.74 MiB/s, done.\n",
            "Resolving deltas: 100% (10829/10829), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.9/dist-packages (8.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (3.7.1)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.9/dist-packages (2.0.6)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.9/dist-packages (2.2.0)\n",
            "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.9/dist-packages (0.1.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.9/dist-packages (0.8.10)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (2.2.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.9/dist-packages (4.65.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.9/dist-packages (2.11.2)\n",
            "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.9/dist-packages (0.1.5.post20221221)\n",
            "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.9/dist-packages (0.1.9)\n",
            "Requirement already satisfied: omegaconf>=2.1 in /usr/local/lib/python3.9/dist-packages (2.3.0)\n",
            "Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.9/dist-packages (1.3.2)\n",
            "Requirement already satisfied: black in /usr/local/lib/python3.9/dist-packages (23.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (23.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (5.12.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.22.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (4.39.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from yacs>=0.1.8) (5.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard) (2.2.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard) (1.51.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard) (63.4.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard) (2.16.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard) (2.27.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tensorboard) (0.40.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard) (0.6.1)\n",
            "Requirement already satisfied: protobuf<4,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorboard) (3.19.6)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.9/dist-packages (from iopath<0.1.10,>=0.1.7) (2.7.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.9/dist-packages (from omegaconf>=2.1) (4.9.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from black) (8.1.3)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from black) (2.0.1)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from black) (0.11.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.9/dist-packages (from black) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.9/dist-packages (from black) (4.5.0)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.9/dist-packages (from black) (3.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard) (6.0.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "qQaaFs327hf5",
        "outputId": "e987ada8-d048-4c96-dfd3-e27b12a0a0db"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n",
            "torch:  1.13 ; cuda:  cu116\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-8229cff19742>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mCUDA_VERSION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"+\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torch: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTORCH_VERSION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"; cuda: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCUDA_VERSION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"detectron2:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'detectron2' has no attribute '__version__'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "import shutil\n",
        "#shutil.move(\"/content/detectron2/detectron2/__init__.py\", \"/content/detectron2/\")\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "\n",
        "#import shutil\n",
        "#shutil.rmtree('/content/detectron2/detectron2')\n"
      ],
      "metadata": {
        "id": "w1VwoHig7n76"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imageFolder = '/content/drive/My Drive/coco/allImages'\n",
        "trainFile = '/content/drive/My Drive/coco/cocojson/train.json'\n",
        "validFile = '/content/drive/My Drive/coco/cocojson/val.json'\n",
        "detectron2.data.datasets.register_coco_instances(\"train\", {}, trainFile, imageFolder)\n",
        "detectron2.data.datasets.register_coco_instances(\"val\", {}, validFile, imageFolder)"
      ],
      "metadata": {
        "id": "CsuNn8jHKyeS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "24ea9842-fb5c-44cf-c657-d7d22bb44013"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ceaf041d2f2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/coco/cocojson/train.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvalidFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/coco/cocojson/val.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_coco_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimageFolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_coco_instances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimageFolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'detectron2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import detectron2.data as data\n",
        "train_metadata = data.MetadataCatalog.get(\"train\")\n",
        "train_data = data.DatasetCatalog.get(\"train\")\n",
        "val_data = data.DatasetCatalog.get(\"val\")\n",
        "num_trainImage = len(train_data)\n",
        "num_valImage = len(val_data)"
      ],
      "metadata": {
        "id": "jYn6MZEX9IMm"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{num_trainImage} training images \\n\"\n",
        "      + f\"{num_valImage} validation images {train_metadata.get('thing_classes')}\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa9f1CcVKlAb",
        "outputId": "a2031288-e6b6-48c0-cc3e-c6fe25438cb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "444 training images \n",
            "111 validation images ['band_member', 'object_e_g_backpacks_belongings', 'observer_non_band_member']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import detectron2.config as config\n",
        "from detectron2 import model_zoo\n",
        "cfg = config.get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
        "# List of the dataset names for training. Must be registered in DatasetCatalog\n",
        "# Samples from these datasets will be merged and used as one dataset.\n",
        "cfg.DATASETS.TRAIN = (\"train\",) #can not omit \",\" ?\n",
        "cfg.DATASETS.TEST = (\"val\",)\n",
        "\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "\n",
        "cfg.DATALOADER.ASPECT_RATIO_GROUPING = False\n",
        "# Use pre-trained weights for transfer learning\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.SOLVER.IMS_PER_BATCH = 8\n",
        "\n",
        "cfg.SOLVER.BASE_LR = 0.0019\n",
        "\n",
        "max_epochs = 100\n",
        "iter_per_epoch = num_trainImage // cfg.SOLVER.IMS_PER_BATCH\n",
        "cfg.SOLVER.MAX_ITER = max_epochs * iter_per_epoch\n",
        "cfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupValLossLR\"\n",
        "cfg.SOLVER.PATIENCE = 7\n",
        "\n",
        "# Things \n",
        "cfg.SOLVER.AMP.ENABLED = False\n",
        "\n",
        "# How often to save a checkpoint while training\n",
        "# 0 to save best model based on minimum val loss\n",
        "cfg.SOLVER.CHECKPOINT_PERIOD = 0\n",
        "cfg.SOLVER.WARMUP_ITERS = 5 \n",
        "# This number should be bigger than the number\n",
        "# of expected objects in each frame\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = (256)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(train_metadata.get(\"thing_classes\"))\n",
        "# NMS threshold used on RPN proposals\n",
        "cfg.MODEL.RPN.NMS_THRESH = .5\n",
        "# How often to check model performance on the validation set\n",
        "# if iter_per_epoch then every epoch\n",
        "cfg.TEST.EVAL_PERIOD = iter_per_epoch * 2\n",
        "# Should be larger than max number of expected objects in image\n",
        "cfg.TEST.DETECTIONS_PER_IMAGE = 200\n",
        "cfg.INPUT.MIN_SIZE_TRAIN = (0)\n",
        "cfg.INPUT.MIN_SIZE_TEST = (0)\n",
        "cfg.INPUT.MAX_SIZE_TRAIN = (4100)\n",
        "cfg.INPUT.MAX_SIZE_TEST = (4100)\n",
        "\n",
        "# Set the data augementation regime\n",
        "cfg.INPUT.CROP.ENABLED = True\n",
        "cfg.INPUT.CROP.TYPE = \"absolute\"\n",
        "cfg.INPUT.CROP.SIZE = (720.0, 720.0) # was 720, 1280\n",
        "cfg.INPUT.RESIZE = False\n",
        "cfg.INPUT.RESIZE_SHAPE = (720, 2048)\n",
        "cfg.INPUT.VER_FLIP = True\n",
        "cfg.INPUT.HOR_FLIP = True\n",
        "cfg.INPUT.AUG_ON_TEST = False\n",
        "cfg.INPUT.CONTRAST = True\n",
        "cfg.INPUT.CONTRAST_RANGE = (.5, 1.5)\n",
        "cfg.INPUT.BRIGHTNESS = True\n",
        "cfg.INPUT.BRIGHTNESS_RANGE = (.3, 1.7)\n",
        "cfg.INPUT.SATURATION = True\n",
        "cfg.INPUT.SATURATION_RANGE = (.7, 1.4)\n",
        "\n",
        "output_name = 'maxiter-{}_lr-{}_detectPerIm-{}_minsize-{}_batchsize-{}_nms-{}'.format(\n",
        "    cfg.SOLVER.MAX_ITER, cfg.SOLVER.BASE_LR, cfg.TEST.DETECTIONS_PER_IMAGE, \n",
        "    np.min(cfg.INPUT.MIN_SIZE_TRAIN), cfg.SOLVER.IMS_PER_BATCH, cfg.MODEL.RPN.NMS_THRESH\n",
        ")\n",
        "cfg.OUTPUT_DIR = os.path.join(cfg.OUTPUT_DIR, output_name)\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Save the config file for future reference\n",
        "yaml_file = os.path.join(cfg.OUTPUT_DIR, \"config.yaml\")\n",
        "with open(yaml_file, 'w') as file:\n",
        "    file.write(cfg.dump())\n",
        "\n"
      ],
      "metadata": {
        "id": "TBJ5yaEnB3w4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "19a61d8d-e10d-4023-d732-c06e9b688c6d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-99c6ff4128cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0miter_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_trainImage\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOLVER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMS_PER_BATCH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOLVER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAX_ITER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0miter_per_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOLVER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLR_SCHEDULER_NAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"WarmupValLossLR\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'num_trainImage' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from DetectionTrainer import DetectionTrainer\n",
        "trainer = DetectionTrainer(cfg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-4oV_E81Rgm",
        "outputId": "3a0780ef-210c-4937-e13c-543d60a23932"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[03/20 18:51:26 d2.engine.defaults]: Model:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "[03/20 18:51:26 detectron2]: CropGen used in training: RandomCrop(crop_type='absolute', crop_size=(720.0, 720.0))\n",
            "Train loader with custom mapper.\n",
            "[03/20 18:51:28 d2.data.datasets.coco]: Loading /content/drive/My Drive/coco/cocojson/train.json takes 2.02 seconds.\n",
            "[03/20 18:51:28 d2.data.datasets.coco]: Loaded 444 images in COCO format from /content/drive/My Drive/coco/cocojson/train.json\n",
            "[03/20 18:51:29 d2.data.build]: Removed 0 images with no usable annotations. 444 images left.\n",
            "[03/20 18:51:30 d2.data.build]: Distribution of instances among all 3 categories:\n",
            "|  category   | #instances   |   category    | #instances   |   category    | #instances   |\n",
            "|:-----------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
            "| band_member | 98404        | object_e_g_.. | 67142        | observer_no.. | 10966        |\n",
            "|             |              |               |              |               |              |\n",
            "|    total    | 176512       |               |              |               |              |\n",
            "[03/20 18:51:30 d2.data.build]: Using training sampler TrainingSampler\n",
            "[03/20 18:51:30 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/20 18:51:30 d2.data.common]: Serializing 444 elements to byte tensors and concatenating them all ...\n",
            "[03/20 18:51:30 d2.data.common]: Serialized dataset takes 10.82 MiB\n",
            "[03/20 18:51:30 d2.data.datasets.coco]: Loaded 111 images in COCO format from /content/drive/My Drive/coco/cocojson/val.json\n",
            "[03/20 18:51:30 d2.data.build]: Distribution of instances among all 3 categories:\n",
            "|  category   | #instances   |   category    | #instances   |   category    | #instances   |\n",
            "|:-----------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
            "| band_member | 24546        | object_e_g_.. | 16438        | observer_no.. | 2889         |\n",
            "|             |              |               |              |               |              |\n",
            "|    total    | 43873        |               |              |               |              |\n",
            "[03/20 18:51:30 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/20 18:51:30 d2.data.common]: Serializing 111 elements to byte tensors and concatenating them all ...\n",
            "[03/20 18:51:30 d2.data.common]: Serialized dataset takes 2.69 MiB\n",
            "hooks: [<detectron2.engine.hooks.IterationTimer object at 0x7fdbb356c460>, <LRScheduler.LRScheduler object at 0x7fdbb27c6d30>, None, <detectron2.engine.hooks.EvalHook object at 0x7fdbb1b25e20>, <LossEvalHook.LossEvalHook object at 0x7fdbb1b25bb0>, <detectron2.engine.hooks.PeriodicWriter object at 0x7fdb711d1f10>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFeKvTr-1f0M",
        "outputId": "cb49adc9-15a2-455b-ee90-39f7dd86c4ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[03/20 18:51:39 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
            "WARNING:fvcore.common.checkpoint:Some model parameters or buffers are not found in the checkpoint:\n",
            "roi_heads.box_predictor.bbox_pred.{bias, weight}\n",
            "roi_heads.box_predictor.cls_score.{bias, weight}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[03/20 18:51:41 d2.engine.train_loop]: Starting training from iteration 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[03/20 18:53:00 d2.utils.events]:  eta: 2:35:35  iter: 19  total_loss: 1.406  loss_cls: 0.5463  loss_box_reg: 0.488  loss_rpn_cls: 0.1604  loss_rpn_loc: 0.2662    time: 3.4118  last_time: 1.2294  data_time: 2.2994  last_data_time: 0.0057   lr: N/A  max_mem: 6179M\n",
            "[03/20 18:53:55 d2.utils.events]:  eta: 3:38:35  iter: 39  total_loss: 1.129  loss_cls: 0.3261  loss_box_reg: 0.4871  loss_rpn_cls: 0.08951  loss_rpn_loc: 0.2443    time: 3.0541  last_time: 5.1937  data_time: 1.3908  last_data_time: 3.8279   lr: N/A  max_mem: 6179M\n",
            "[03/20 18:54:48 d2.utils.events]:  eta: 3:37:47  iter: 59  total_loss: 1.118  loss_cls: 0.311  loss_box_reg: 0.4674  loss_rpn_cls: 0.09913  loss_rpn_loc: 0.2503    time: 2.9143  last_time: 3.3141  data_time: 1.2421  last_data_time: 1.9803   lr: N/A  max_mem: 6179M\n",
            "[03/20 18:55:42 d2.utils.events]:  eta: 3:36:59  iter: 79  total_loss: 1.034  loss_cls: 0.2618  loss_box_reg: 0.4581  loss_rpn_cls: 0.08839  loss_rpn_loc: 0.2291    time: 2.8540  last_time: 4.9341  data_time: 1.2508  last_data_time: 3.5478   lr: N/A  max_mem: 6179M\n",
            "[03/20 18:56:33 d2.utils.events]:  eta: 3:36:11  iter: 99  total_loss: 1.026  loss_cls: 0.2437  loss_box_reg: 0.4522  loss_rpn_cls: 0.08269  loss_rpn_loc: 0.2304    time: 2.7967  last_time: 3.0011  data_time: 1.1768  last_data_time: 1.6581   lr: N/A  max_mem: 6179M\n",
            "[03/20 18:57:02 d2.data.datasets.coco]: Loading /content/drive/My Drive/coco/cocojson/val.json takes 1.38 seconds.\n",
            "[03/20 18:57:02 d2.data.datasets.coco]: Loaded 111 images in COCO format from /content/drive/My Drive/coco/cocojson/val.json\n",
            "[03/20 18:57:02 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "[03/20 18:57:02 d2.data.common]: Serializing 111 elements to byte tensors and concatenating them all ...\n",
            "[03/20 18:57:02 d2.data.common]: Serialized dataset takes 2.69 MiB\n",
            "[03/20 18:57:02 d2.evaluation.coco_evaluation]: Fast COCO eval is not built. Falling back to official COCO eval.\n",
            "WARNING [03/20 18:57:02 d2.evaluation.coco_evaluation]: COCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
            "[03/20 18:57:02 d2.evaluation.evaluator]: Start inference on 111 batches\n",
            "[03/20 18:57:17 d2.evaluation.evaluator]: Inference done 11/111. Dataloading: 0.0176 s/iter. Inference: 0.8624 s/iter. Eval: 0.0005 s/iter. Total: 0.8805 s/iter. ETA=0:01:28\n",
            "[03/20 18:57:23 d2.evaluation.evaluator]: Inference done 17/111. Dataloading: 0.0199 s/iter. Inference: 0.8688 s/iter. Eval: 0.0005 s/iter. Total: 0.8893 s/iter. ETA=0:01:23\n",
            "[03/20 18:57:28 d2.evaluation.evaluator]: Inference done 23/111. Dataloading: 0.0293 s/iter. Inference: 0.8807 s/iter. Eval: 0.0005 s/iter. Total: 0.9107 s/iter. ETA=0:01:20\n",
            "[03/20 18:57:34 d2.evaluation.evaluator]: Inference done 29/111. Dataloading: 0.0278 s/iter. Inference: 0.8786 s/iter. Eval: 0.0005 s/iter. Total: 0.9071 s/iter. ETA=0:01:14\n",
            "[03/20 18:57:39 d2.evaluation.evaluator]: Inference done 35/111. Dataloading: 0.0271 s/iter. Inference: 0.8809 s/iter. Eval: 0.0005 s/iter. Total: 0.9087 s/iter. ETA=0:01:09\n",
            "[03/20 18:57:45 d2.evaluation.evaluator]: Inference done 41/111. Dataloading: 0.0285 s/iter. Inference: 0.8808 s/iter. Eval: 0.0005 s/iter. Total: 0.9101 s/iter. ETA=0:01:03\n",
            "[03/20 18:57:50 d2.evaluation.evaluator]: Inference done 47/111. Dataloading: 0.0273 s/iter. Inference: 0.8769 s/iter. Eval: 0.0005 s/iter. Total: 0.9050 s/iter. ETA=0:00:57\n",
            "[03/20 18:57:56 d2.evaluation.evaluator]: Inference done 53/111. Dataloading: 0.0285 s/iter. Inference: 0.8773 s/iter. Eval: 0.0005 s/iter. Total: 0.9066 s/iter. ETA=0:00:52\n",
            "[03/20 18:58:01 d2.evaluation.evaluator]: Inference done 59/111. Dataloading: 0.0293 s/iter. Inference: 0.8755 s/iter. Eval: 0.0005 s/iter. Total: 0.9058 s/iter. ETA=0:00:47\n",
            "[03/20 18:58:06 d2.evaluation.evaluator]: Inference done 65/111. Dataloading: 0.0287 s/iter. Inference: 0.8724 s/iter. Eval: 0.0005 s/iter. Total: 0.9021 s/iter. ETA=0:00:41\n",
            "[03/20 18:58:12 d2.evaluation.evaluator]: Inference done 71/111. Dataloading: 0.0300 s/iter. Inference: 0.8725 s/iter. Eval: 0.0006 s/iter. Total: 0.9036 s/iter. ETA=0:00:36\n",
            "[03/20 18:58:17 d2.evaluation.evaluator]: Inference done 77/111. Dataloading: 0.0307 s/iter. Inference: 0.8702 s/iter. Eval: 0.0006 s/iter. Total: 0.9020 s/iter. ETA=0:00:30\n",
            "[03/20 18:58:22 d2.evaluation.evaluator]: Inference done 83/111. Dataloading: 0.0299 s/iter. Inference: 0.8676 s/iter. Eval: 0.0006 s/iter. Total: 0.8986 s/iter. ETA=0:00:25\n",
            "[03/20 18:58:28 d2.evaluation.evaluator]: Inference done 89/111. Dataloading: 0.0316 s/iter. Inference: 0.8685 s/iter. Eval: 0.0006 s/iter. Total: 0.9012 s/iter. ETA=0:00:19\n",
            "[03/20 18:58:33 d2.evaluation.evaluator]: Inference done 95/111. Dataloading: 0.0314 s/iter. Inference: 0.8672 s/iter. Eval: 0.0006 s/iter. Total: 0.8997 s/iter. ETA=0:00:14\n",
            "[03/20 18:58:38 d2.evaluation.evaluator]: Inference done 101/111. Dataloading: 0.0309 s/iter. Inference: 0.8660 s/iter. Eval: 0.0006 s/iter. Total: 0.8979 s/iter. ETA=0:00:08\n",
            "[03/20 18:58:44 d2.evaluation.evaluator]: Inference done 107/111. Dataloading: 0.0318 s/iter. Inference: 0.8677 s/iter. Eval: 0.0006 s/iter. Total: 0.9007 s/iter. ETA=0:00:03\n",
            "[03/20 18:58:47 d2.evaluation.evaluator]: Total inference time: 0:01:35.454717 (0.900516 s / iter per device, on 1 devices)\n",
            "[03/20 18:58:47 d2.evaluation.evaluator]: Total inference pure compute time: 0:01:31 (0.867287 s / iter per device, on 1 devices)\n",
            "[03/20 18:58:48 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
            "[03/20 18:58:48 d2.evaluation.coco_evaluation]: Saving results to ./output/maxiter-5500_lr-0.0019_detectPerIm-200_minsize-0_batchsize-8_nms-0.5/inference/coco_instances_results.json\n",
            "[03/20 18:58:48 d2.evaluation.coco_evaluation]: Evaluating predictions with official COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=67.51s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.24s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.053\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.135\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.025\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.053\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.052\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.011\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.073\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.068\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.073\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
            "[03/20 18:59:55 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
            "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
            "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
            "| 5.256 | 13.479 | 2.503  | 5.319 | 5.249 | 0.000 |\n",
            "[03/20 18:59:55 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
            "| category    | AP     | category                        | AP    | category                 | AP    |\n",
            "|:------------|:-------|:--------------------------------|:------|:-------------------------|:------|\n",
            "| band_member | 14.709 | object_e_g_backpacks_belongings | 1.059 | observer_non_band_member | 0.000 |\n",
            "[03/20 18:59:56 d2.engine.defaults]: Evaluation results for val in csv format:\n",
            "[03/20 18:59:56 d2.evaluation.testing]: copypaste: Task: bbox\n",
            "[03/20 18:59:56 d2.evaluation.testing]: copypaste: AP,AP50,AP75,APs,APm,APl\n",
            "[03/20 18:59:56 d2.evaluation.testing]: copypaste: 5.2559,13.4785,2.5027,5.3191,5.2495,0.0000\n",
            "[03/20 18:59:58 d2.utils.memory]: Attempting to copy inputs of <function pairwise_iou at 0x7fdbc7145670> to CPU due to CUDA OOM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from DetectionDatasetMapper import DetectionDatasetMapper\n",
        "from detectron2.engine import DefaultPredictor\n",
        "import random\n"
      ],
      "metadata": {
        "id": "JA0ZzDUTLDOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Check training quality\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"best-model-config-iter-896-loss-0.8034359399295811.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "cfg.DATASETS.TEST = (\"val\", )\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "for d in random.sample(val_data, 3):\n",
        "# for d in train_dicts:\n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=train_metadata,\n",
        "                   scale=0.8,\n",
        "                   \n",
        "    )\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    plt.figure(figsize=(20,20))\n",
        "    plt.imshow(v.get_image()[:, :, ::])"
      ],
      "metadata": {
        "id": "Xju3e1xh1I62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from inference import register_inference_instances, nms_all_classes\n",
        "from detectron2.data import build_detection_test_loader\n",
        "from detectron2.modeling import build_model\n",
        "from detectron2.checkpoint import DetectionCheckpointer\n"
      ],
      "metadata": {
        "id": "M7wZddIkNak6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build model\n",
        "model = build_model(cfg)\n",
        "_ = model.eval()\n",
        "\n",
        "checkpointer = DetectionCheckpointer(model)\n",
        "_ = checkpointer.load(cfg.MODEL.WEIGHTS)\n"
      ],
      "metadata": {
        "id": "h4AgVokxPHRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict with frames extracted from the videos\n",
        "pathName = '/content/drive/My Drive/Drone Footage_Coding Task/Drone Footage/11 9 flights/'\n",
        "videos = glob.glob(pathName + '*.MP4')\n",
        "videos = videos[0:13]\n",
        "for video in videos:\n",
        "  videoName = video.split('/')[7].split('.')[0]\n",
        "  outFolder = '/content/drive/My Drive/Frames/'+ videoName\n",
        "  resultFolder = '/content/drive/My Drive/Frames/Result'\n",
        "  os.makedirs(resultFolder, exist_ok = True)\n",
        "  register_inference_instances(\"inference\", outFolder)\n",
        "  mapper = DetectionDatasetMapper(cfg, is_train = False)\n",
        "  loader = build_detection_test_loader(cfg, \"inference\", mapper = mapper)\n",
        "  for batch in loader:\n",
        "    image = batch[0]['image'].numpy()\n",
        "    image = np.transpose(image, [1, 2, 0])\n",
        "    plt.figure(figsize = (20, 20))\n",
        "    plt.imshow(image[..., ::-1].astype(np.uint8))\n",
        "    break\n",
        "  all_detections = []\n",
        "\n",
        "  t = time.time()\n",
        "  with torch.no_grad():\n",
        "      for batch_num, image_batch in enumerate(loader):\n",
        "          #if batch_num % 500 == 0:\n",
        "            #  print(f\"{batch_num} images processed.\")\n",
        "          detections = model(image_batch)\n",
        "          for ind, detection in enumerate(detections):\n",
        "              instances = detection[\"instances\"]\n",
        "              # Postprocessing (non-maximum supression across all classes)\n",
        "              instances = nms_all_classes(instances, iou_thresh=.5)\n",
        "              detections[ind][\"instances\"] = instances\n",
        "\n",
        "          detection_dict = detections[0]['instances'].get_fields()\n",
        "          detection_dict['pred_boxes'] = detection_dict['pred_boxes'].tensor.cpu().numpy()\n",
        "          detection_dict['scores'] = detection_dict['scores'].cpu().numpy()\n",
        "          detection_dict['pred_classes'] = detection_dict['pred_classes'].cpu().numpy()\n",
        "          detection_dict['image_name'] = os.path.basename(image_batch[0]['file_name'])\n",
        "          all_detections.append(detection_dict)\n",
        "\n",
        "  np_detections_file = os.path.join(resultFolder, '{}_detections.npy'.format(videoName))\n",
        "  np.save(np_detections_file, all_detections)  \n",
        "  print(time.time() - t)\n",
        "  image = image_batch[0]['image'].numpy()\n",
        "  image = np.transpose(image, [1, 2, 0])\n",
        "\n",
        "  v = Visualizer(image[...,::-1],\n",
        "                metadata=None,\n",
        "                scale=1.0,\n",
        "  )\n",
        "  v = v.draw_instance_predictions(detections[0]['instances'])\n",
        "  plt.figure(figsize=(20,20))\n",
        "  plt.imshow(v.get_image())"
      ],
      "metadata": {
        "id": "AD7f02xWLz3K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}